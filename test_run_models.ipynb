{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate GPU Installation (NVIDIA ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge cudatoolkit=11.2 cudnn=8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Mon_Oct_12_20:54:10_Pacific_Daylight_Time_2020\n",
      "Cuda compilation tools, release 11.1, V11.1.105\n",
      "Build cuda_11.1.relgpu_drvr455TC455_06.29190527_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If conda install gpu doesnt work, use the following steps:\n",
    "1. Go to this [link](https://developer.nvidia.com/rdp/cudnn-archive) and install cuDNN 8.1.1.\n",
    "2. Extract the files.\n",
    "3. Copy `bin\\cudnn64_8.dll` → `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin`\n",
    "4. Copy `lib\\x64\\cudnn.lib` → `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\lib\\x64`\n",
    "5. Copy `include\\cudnn.h` → `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\include`\n",
    "6. Open **Windows Environment Variables**, and **Add these paths**:\n",
    "```bash\n",
    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin\n",
    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\libnvvm\\bin\n",
    "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\include\n",
    "```\n",
    "7. Verify\n",
    "```bash\n",
    "where cudnn64_8.dll\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more steps:\n",
    "1. Move the nvvm folder into /models/research in the Tensorflow Object Detection API directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run fine-tuned model (ssd mobilenet v2 fpnlite 320x320 coco17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "# Load the label map\n",
    "label_map_path = \"./mtsd_data/mtsd_label_map.pbtxt\"\n",
    "category_index = label_map_util.create_category_index_from_labelmap(label_map_path, use_display_name=True)\n",
    "\n",
    "# Load the saved model\n",
    "detect_fn = tf.saved_model.load(\"./models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/exported_model/saved_model\")\n",
    "\n",
    "# Function to draw bounding boxes and labels inside the boxes\n",
    "def draw_boxes_with_labels(image, boxes, classes, scores, category_index, min_score_thresh=0.4):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes and labels inside the boxes on the given image.\n",
    "    \n",
    "    Args:\n",
    "        image: The image to draw on.\n",
    "        boxes: Bounding box coordinates (normalized) from the model.\n",
    "        classes: Detected class indices.\n",
    "        scores: Detection scores.\n",
    "        category_index: Mapping of class indices to class names.\n",
    "        min_score_thresh: Minimum score threshold for displaying detections.\n",
    "    \n",
    "    Returns:\n",
    "        Annotated image with bounding boxes and labels inside.\n",
    "    \"\"\"\n",
    "    height, width, _ = image.shape\n",
    "    for i in range(len(boxes)):\n",
    "        if scores[i] >= min_score_thresh:\n",
    "            # Scale the box to image dimensions\n",
    "            ymin, xmin, ymax, xmax = boxes[i]\n",
    "            xmin = int(xmin * width)\n",
    "            xmax = int(xmax * width)\n",
    "            ymin = int(ymin * height)\n",
    "            ymax = int(ymax * height)\n",
    "            \n",
    "            # Draw the rectangle\n",
    "            color = (0, 255, 0)  # Green color\n",
    "            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "\n",
    "            # Get the label text\n",
    "            class_id = int(classes[i])\n",
    "            class_name = category_index[class_id]['name']\n",
    "            label = f\"{class_name}: {scores[i]:.2f}\"\n",
    "\n",
    "            # Calculate text size\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = 0.5\n",
    "            font_thickness = 1\n",
    "            text_size = cv2.getTextSize(label, font, font_scale, font_thickness)[0]\n",
    "\n",
    "            # Text background coordinates (inside the bounding box)\n",
    "            text_x = xmin + 2\n",
    "            text_y = ymin + text_size[1] + 2\n",
    "            text_bg_x = text_x + text_size[0]\n",
    "            text_bg_y = text_y - text_size[1]\n",
    "\n",
    "            # Draw text background rectangle (inside the box)\n",
    "            cv2.rectangle(image, (xmin, ymin), (text_bg_x, text_bg_y), color, -1)\n",
    "\n",
    "            # Draw the label text (inside the box)\n",
    "            cv2.putText(\n",
    "                image,\n",
    "                label,\n",
    "                (text_x, text_y),\n",
    "                font,\n",
    "                font_scale,\n",
    "                (0, 255, 0),  # Black text\n",
    "                font_thickness,\n",
    "                lineType=cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "    return image\n",
    "\n",
    "# Load an image\n",
    "image_path = \"./mtsd_data/mtsd_images/02_PNG_jpg.rf.70c5e13b9fadb831af5abb7e7bf33c2e.jpg\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Convert the image to a tensor\n",
    "input_tensor = tf.convert_to_tensor(image)\n",
    "input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# Perform detection\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "# Extract detection details\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "boxes = detections['detection_boxes']\n",
    "scores = detections['detection_scores']\n",
    "classes = detections['detection_classes'].astype(np.int32)\n",
    "\n",
    "# Draw detections on the image\n",
    "annotated_image = draw_boxes_with_labels(\n",
    "    image=image.copy(), \n",
    "    boxes=boxes, \n",
    "    classes=classes, \n",
    "    scores=scores, \n",
    "    category_index=category_index, \n",
    "    min_score_thresh=0.4\n",
    ")\n",
    "\n",
    "# Display the image with detections\n",
    "cv2.imshow(\"Detections\", annotated_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
